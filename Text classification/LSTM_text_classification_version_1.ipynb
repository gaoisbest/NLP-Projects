{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this series (includes three parts), I focus on text classification task based on Recurrent Neural Networks (RNNs). From part 1 to part 3, I will add more concepts to deal with more sophisticated scenarios gradually.\n",
    "\n",
    "If you are not familiar with concepts of RNNs, the following list gives popular tutorials about RNNs:\n",
    "- Christopher Olah's [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "- Andrej Karpathy's [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "- R2RT's [Recurrent Neural Networks in Tensorflow I II III](https://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html)\n",
    "- Danijar Hafner's [Introduction to Recurrent Networks in TensorFlow](https://danijar.com/introduction-to-recurrent-networks-in-tensorflow)\n",
    "- Denny Britz's [Recurrent Neural Networks Tutorial, Part 1 – Introduction to RNNs](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/)\n",
    "\n",
    "The example data used in this series is from [Sogou](http://www.sogou.com/labs/resource/cs.php) corpus. I have downloaded the data, performed duplicates removing, Chinese word segmentation, stopwords removing etc. The example data used here includes six categories, i.e, `{1:auto, 2:business, 3: it, 4:health; 5:sports, 6:yule}`. Each category includes `training_x.cs` (contains `15,000` articles) and `testing_x.cs` (contains `3,000` articles). You can download the data from [here](http://pan.baidu.com/s/1hs27uHA).\n",
    "\n",
    "Core concepts in part 1:\n",
    "- One layer RNNs, which includes **three cell types**: `tf.contrib.rnn.BasicRNNCell`, `tf.contrib.rnn.BasicLSTMCell` and `tf.contrib.rnn.GRUCell`), are used. \n",
    "- The length of input sequences (means articles here) is **fixed**. \n",
    "- The inputs and outputs of `outputs, last_state = tf.contrib.rnn.static_rnn(cell, inputs)` is a **list**. \n",
    "- **`outputs[-1]`** means the output at last time step. `outputs[-1]` is focused since we only interests on the output of RNNs at last time step for classification task.\n",
    "- For one layer RNNs, **`outputs[-1] == last_state`** for `BasicLSTMCell` and `GRUCell`. **`output[-1] == last_state.h`** for `BasicLSTMCell`. Why ? See below.\n",
    "- Two `tf.summary.FileWriter` are initialized to save `accuracy` and `loss` of both **training** and **testing** steps to TensorBoard.\n",
    "- Tensorflow model architecture (followed from [here](https://danijar.com/structuring-your-tensorflow-models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from random import shuffle\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class `DataGenerator` is used to read input files, convert words to index and generate batch training or testing data. \n",
    "\n",
    "Since the RNNs input has fixed length. Longer sequences are truncated to `Arguments.MAX_SEQ_LENGTH` and shorter sequences are padded to `Arguments.MAX_SEQ_LENGTH`. \n",
    "\n",
    "Two extra word are introduced, `PAD` for padding shorter sequences and `OOV` for representing out-of-vocabulary words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataGenerator():\n",
    "    \"\"\"\n",
    "    reading each training and testing files, and generating batch data.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        self.folder_path = args.FOLDER_PATH\n",
    "        self.batch_size = args.BATCH_SIZE\n",
    "        self.vocab_size = args.VOCAB_SIZE\n",
    "        self.max_seq_len = args.MAX_SEQ_LENGTH\n",
    "        self.num_epoch = args.NUM_EPOCH\n",
    "        self.read_build_input()\n",
    "        self.single_generator_training = self.generate_sample_training()\n",
    "        self.single_generator_testing = self.generate_sample_testing()\n",
    "        self.label_dict = {0:'auto', 1:'business', 2:'IT', 3:'health', 4:'sports', 5:'yule'}\n",
    "        \n",
    "        \n",
    "    def read_build_input(self):\n",
    "        training_src = []\n",
    "        testing_src = []\n",
    "        article_len = []\n",
    "\n",
    "        for cur_category in range(1, 7):\n",
    "            \n",
    "            print('parsing file >>>>>>>>>>>>>>> ', cur_category)\n",
    "            print('-'*100)\n",
    "            \n",
    "            training_input_file = codecs.open(filename=os.path.join(self.folder_path, 'training_' + str(cur_category) + '.cs'), mode='r', encoding='utf-8')\n",
    "            for tmp_line in training_input_file:\n",
    "                training_src.append((tmp_line.split(), cur_category-1))\n",
    "                article_len.append(len(tmp_line.split()))\n",
    "\n",
    "            testing_input_file = codecs.open(filename=os.path.join(self.folder_path, 'testing_' + str(cur_category) + '.cs'), mode='r', encoding='utf-8')\n",
    "            for tmp_line in testing_input_file:\n",
    "                testing_src.append((tmp_line.split(), cur_category-1))\n",
    "                article_len.append(len(tmp_line.split()))\n",
    "\n",
    "        shuffle(training_src)\n",
    "        shuffle(testing_src)\n",
    "        \n",
    "        assert(len(article_len) == (len(training_src) + len(testing_src)))\n",
    "        print('='*100)\n",
    "        print('Size of training data:', len(training_src))\n",
    "        print('Size of testing data:', len(testing_src))\n",
    "        print('Average length of all articles', sum(article_len)/len(article_len))\n",
    "    \n",
    "        self.TRAINING_SIZE = len(training_src)\n",
    "        args.TESTING_SIZE = len(testing_src)\n",
    "        \n",
    "        training_X_src = [pair[0] for pair in training_src]\n",
    "        testing_X_src = [pair[0] for pair in testing_src]\n",
    "        all_data = list(itertools.chain.from_iterable(training_X_src + testing_X_src))\n",
    "        word_counter = Counter(all_data).most_common(self.vocab_size)\n",
    "        del all_data\n",
    "        \n",
    "        print('='*100)\n",
    "        print('top 10 frequent words:')\n",
    "        print(word_counter[0:10])\n",
    "        self.word2idx = {val[0]: idx+1 for idx, val in enumerate(word_counter)}\n",
    "        self.word2idx['PAD'] = 0 # padding word\n",
    "        self.word2idx['OOV'] = self.vocab_size + 1 # out-of-vocabulary\n",
    "        self.idx2word = dict(zip(self.word2idx.values(), self.word2idx.keys()))\n",
    "        print('Total vocabulary size:{}'.format(len(self.word2idx)))\n",
    "        \n",
    "        self.training = [([self.word2idx[w] if w in self.word2idx else self.word2idx['OOV'] for w in tmp_pair[0][0:self.max_seq_len]], tmp_pair[1]) for tmp_pair in training_src]\n",
    "        self.testing_ori =  [([self.word2idx[w] if w in self.word2idx else self.word2idx['OOV'] for w in tmp_pair[0][0:self.max_seq_len]], tmp_pair[1]) for tmp_pair in testing_src]\n",
    "        self.testing = [(tmp_pair[0] + [self.word2idx['PAD']] * (self.max_seq_len - len(tmp_pair[0])), tmp_pair[1]) if len(tmp_pair[0]) < self.max_seq_len else tmp_pair for tmp_pair in self.testing_ori]\n",
    "    \n",
    "    def generate_sample_training(self):\n",
    "        \"\"\"\n",
    "        If len(each article) < self.max_seq_len:\n",
    "            padding them with 0\n",
    "        else:\n",
    "            truncating them to self.max_seq_len\n",
    "        \"\"\"\n",
    "        outer_index = 0\n",
    "        for X_y_pair in itertools.cycle(self.training):  # infinite loop each article\n",
    "            tmp_input_len = len(X_y_pair[0])\n",
    "            if tmp_input_len < self.max_seq_len:\n",
    "                input_X = X_y_pair[0] + [self.word2idx['PAD']] * (self.max_seq_len - tmp_input_len)\n",
    "            else:\n",
    "                input_X = X_y_pair[0]\n",
    "            \n",
    "            output_y = X_y_pair[1]\n",
    "            if outer_index in [0, self.batch_size-1]:\n",
    "                print('='*100)\n",
    "                print('Training text:', ' '.join([self.idx2word[tmp_id] for tmp_id in input_X]))\n",
    "                print('Training text length:', len(input_X))\n",
    "                print('Training label:', self.label_dict[output_y])\n",
    "                \n",
    "            yield input_X, output_y\n",
    "            outer_index += 1\n",
    "    \n",
    "    def generate_sample_testing(self):\n",
    "        \"\"\"\n",
    "        If len(each article) < self.max_seq_len:\n",
    "            padding them with 0\n",
    "        else:\n",
    "            truncating them to self.max_seq_len\n",
    "        \"\"\"\n",
    "        outer_index = 0\n",
    "        for X_y_pair in itertools.cycle(self.testing):  # infinite loop each article\n",
    "            tmp_input_len = len(X_y_pair[0])\n",
    "            if tmp_input_len < self.max_seq_len:\n",
    "                input_X = X_y_pair[0] + [self.word2idx['PAD']] * (self.max_seq_len - tmp_input_len)\n",
    "            else:\n",
    "                input_X = X_y_pair[0]\n",
    "            \n",
    "            output_y = X_y_pair[1]\n",
    "            if outer_index in [0, self.batch_size-1]:\n",
    "                print('='*100)\n",
    "                print('Testing text:', ' '.join([self.idx2word[tmp_id] for tmp_id in input_X]))\n",
    "                print('Testing text length:', len(input_X))\n",
    "                print('Testing label:', self.label_dict[output_y])\n",
    "                \n",
    "            yield input_X, output_y\n",
    "            outer_index += 1\n",
    "        \n",
    "\n",
    "    def next_batch_training(self):\n",
    "        input_X_batch = []\n",
    "        output_y_batch = []\n",
    "        for idx in range(self.batch_size):\n",
    "            tmp_X, tmp_y = next(self.single_generator_training)\n",
    "            input_X_batch.append(tmp_X)\n",
    "            output_y_batch.append(tmp_y)\n",
    "        return np.array(input_X_batch, dtype=np.int32), np.array(output_y_batch, dtype=np.int32)\n",
    "    \n",
    "    def next_testing(self):\n",
    "        testing_X = np.array([tmp_pair[0] for tmp_pair in self.testing], dtype=np.int32)\n",
    "        testing_y = np.array([tmp_pair[1] for tmp_pair in self.testing], dtype=np.int32)\n",
    "        return testing_X, testing_y        \n",
    "    \n",
    "    def next_batch_testing(self):\n",
    "        input_X_batch = []\n",
    "        output_y_batch = []\n",
    "        for idx in range(self.batch_size):\n",
    "            tmp_X, tmp_y = next(self.single_generator_testing)\n",
    "            input_X_batch.append(tmp_X)\n",
    "            output_y_batch.append(tmp_y)\n",
    "        return np.array(input_X_batch, dtype=np.int32), np.array(output_y_batch, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper-parameters for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Arguments:\n",
    "    \"\"\"\n",
    "    main hyper-parameters\n",
    "    \"\"\"\n",
    "    MAX_SEQ_LENGTH = 150 # since Average length of all articles around 143\n",
    "    EMBED_SIZE = 128 # embedding dimensions\n",
    "    BATCH_SIZE = 64\n",
    "    VOCAB_SIZE = 300000 # vocabulary size\n",
    "    NUM_CLASSES = 6 # number of classes\n",
    "    FOLDER_PATH = 'sogou_corpus'\n",
    "    NUM_EPOCH = 7\n",
    "    RNN_TYPE = 'LSTM' # RNN, LSTM or GRU\n",
    "    CHECKPOINTS_DIR = 'text_classification_LSTM_model'\n",
    "    LOGDIR = 'text_classification_LSTM_logdir'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function for better organizing Tensorflow model structure.\n",
    "\n",
    "From https://danijar.com/structuring-your-tensorflow-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "def lazy_property(function):\n",
    "    \"\"\"\n",
    "    helper function from https://danijar.com/structuring-your-tensorflow-models\n",
    "    \"\"\"\n",
    "    attribute = '_cache_' + function.__name__\n",
    "\n",
    "    @property\n",
    "    @functools.wraps(function)\n",
    "    def decorator(self):\n",
    "        if not hasattr(self, attribute):\n",
    "            setattr(self, attribute, function(self))\n",
    "        return getattr(self, attribute)\n",
    "\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class `TextClassificationModel` defines main model, which includes `input_output`, `RNNs_model`, `score`, `cost` and `optimizer`. \n",
    "\n",
    "One layer RNNs with `tf.contrib.rnn.static_rnn` is used.\n",
    "\n",
    "### `outputs, last_state = tf.contrib.rnn.static_rnn(cell, inputs, initial_state)`\n",
    "\n",
    "- `inputs` is a `list`, which size is `num_steps` and shape of each element is `[batch_size, num_units]`.\n",
    "\n",
    "- `outputs` is a `list`, which size is `num_steps` and contains the output (i.e., `ht`) at each time step. The shape of each `outputs` element is `[batch_size, num_units]`.\n",
    "\n",
    "- Let `ht` and `ct` be the hidden state and cell state at time step *t*, respectively.\n",
    "\n",
    "- For one layer RNNs, `last_state` is a `Tensor` or a `LSTMStateTuple` in different scenarios.\n",
    "\n",
    "#### For `BasicRNNCell` and `GRUCell`\n",
    "- one layer\n",
    "    - Both `output[-1]` and `last_state` are `ht` at last time step\n",
    "    - **`output[-1] == last_state`**\n",
    "    - For instance: \n",
    "    ```\n",
    "    BasicRNNCell:\n",
    "    output[-1]: \n",
    "    Tensor(\"model/rnn/rnn/basic_rnn_cell/Tanh_199:0\", shape=(32, 128), dtype=float32)    \n",
    "    last_state: \n",
    "    Tensor(\"model/rnn/rnn/basic_rnn_cell/Tanh_199:0\", shape=(32, 128), dtype=float32)\n",
    "    \n",
    "    GRUCell:\n",
    "    output[-1]:\n",
    "    Tensor(\"model/rnn/rnn/gru_cell/add_199:0\", shape=(32, 128), dtype=float32)\n",
    "    last_state:\n",
    "    Tensor(\"model/rnn/rnn/gru_cell/add_199:0\", shape=(32, 128), dtype=float32)\n",
    "    ```\n",
    "\n",
    "#### For `BasicLSTMCell`\n",
    "- One layer\n",
    "    - `output[-1]` is `ht` at last time step\n",
    "    - `last_state` is `LSTMStateTuple(ct, ht)` at last time step\n",
    "    - **`output[-1] == last_state.h`**\n",
    "    - For instance:\n",
    "    ```\n",
    "    output[-1]:\n",
    "    Tensor(\"model/rnn/rnn/basic_lstm_cell/mul_599:0\", shape=(32, 128), dtype=float32)\n",
    "\n",
    "    last_state: \n",
    "    LSTMStateTuple(c=<tf.Tensor 'model/rnn/rnn/basic_lstm_cell/add_399:0' shape=(32, 128) dtype=float32>, h=<tf.Tensor 'model/rnn/rnn/basic_lstm_cell/mul_599:0' shape=(32, 128) dtype=float32>)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextClassificationModel:\n",
    "    \"\"\"\n",
    "    Model class.\n",
    "    \"\"\"\n",
    "    def __init__(self, args, is_training=True):\n",
    "        self.num_units = args.EMBED_SIZE\n",
    "        self.batch_size = args.BATCH_SIZE\n",
    "        self.rnn_type = args.RNN_TYPE\n",
    "        self.is_training = is_training\n",
    "        \n",
    "        if self.is_training:\n",
    "            self.batch_size = args.BATCH_SIZE\n",
    "        else:\n",
    "            self.batch_size = args.TESTING_SIZE\n",
    "        \n",
    "        self.num_classes = args.NUM_CLASSES\n",
    "        self.vocab_size = args.VOCAB_SIZE + 2\n",
    "        self.num_steps = args.MAX_SEQ_LENGTH\n",
    "        self.global_step = tf.Variable(initial_value=0, dtype=tf.int32, trainable=False, name='global_step')\n",
    "\n",
    "        self.input_output\n",
    "        self.model\n",
    "        self.score\n",
    "        self.cost\n",
    "        self.optimizer\n",
    "        \n",
    "    @lazy_property\n",
    "    def input_output(self):\n",
    "        with tf.name_scope('input_output'):\n",
    "            input_X = tf.placeholder(dtype=tf.int32, shape=[self.batch_size, self.num_steps], name='input_X')\n",
    "            output_y = tf.placeholder(dtype=tf.int32, shape = [self.batch_size], name='output_y')\n",
    "        return (input_X, output_y)\n",
    "                \n",
    "        \n",
    "    @lazy_property\n",
    "    def model(self):\n",
    "        \n",
    "        with tf.name_scope('RNNs_model'):\n",
    "            with tf.variable_scope('embedding'):\n",
    "                with tf.device('/cpu:0'):\n",
    "                    embedding_matrix = tf.get_variable(name='embedding_matrix', shape=[self.vocab_size, self.num_units])\n",
    "                    # inputs shape: (self.batch_size, self.num_steps, self.num_units)\n",
    "                    inputs = tf.nn.embedding_lookup(params=embedding_matrix, ids=self.input_output[0], name='embed')\n",
    "\n",
    "            if self.rnn_type == 'RNN':\n",
    "                cell = tf.contrib.rnn.BasicRNNCell(num_units=self.num_units)\n",
    "            elif self.rnn_type == 'GRU':\n",
    "                cell = tf.contrib.rnn.GRUCell(num_units=self.num_units)\n",
    "            elif self.rnn_type == 'LSTM':\n",
    "                cell = tf.contrib.rnn.BasicLSTMCell(num_units=self.num_units)\n",
    "            else:\n",
    "                raise ValueError('The input rnn type is undefined.')\n",
    "                \n",
    "            initial_state = cell.zero_state(batch_size=self.batch_size, dtype=tf.float32)            \n",
    "           \n",
    "            inputs = tf.unstack(inputs, self.num_steps, 1)            \n",
    "            \n",
    "            print('='*100)\n",
    "            print('static_rnn inputs type:', type(inputs)) # list\n",
    "            print('static_rnn inputs len:', len(inputs)) # self.num_steps\n",
    "            print('static_rnn inputs element type:', type(inputs[0])) # Tensor\n",
    "            print('static_rnn inputs element shape:', inputs[0].get_shape) # [self.batch_size, self.num_units]\n",
    "            print('='*100)\n",
    "\n",
    "\n",
    "            outputs, last_state = tf.contrib.rnn.static_rnn(cell, inputs=inputs, initial_state=initial_state)\n",
    "            \n",
    "            print('static_rnn output type:', type(outputs)) # list\n",
    "            print('static_rnn output length:', len(outputs)) # self.num_steps\n",
    "            print('static_rnn output element type:', type(outputs[-1])) # Tensor, output[-1] is last hidden state (i.e., hidden state at (self.num_steps - 1))\n",
    "            print('static_rnn output element shape:', outputs[-1].get_shape()) # [self.batch_size, self.num_units]                \n",
    "            print('static_rnn last_state type:', type(last_state)) # \n",
    "            print('last_state:', last_state) # (self.batch_size, self.num_units)\n",
    "            print('='*100)\n",
    "            \n",
    "            if self.rnn_type == 'RNN' or self.rnn_type == 'GRU':\n",
    "                print('outputs[-1] == last_state', outputs[-1] == last_state)\n",
    "            elif self.rnn_type == 'LSTM':\n",
    "                print('outputs[-1] == last_state.h', outputs[-1] == last_state.h)\n",
    "            else:\n",
    "                raise ValueError('The input rnn type is undefined.')\n",
    "\n",
    "        return (outputs, last_state)\n",
    "    \n",
    "    @lazy_property\n",
    "    def score(self):\n",
    "        \n",
    "        with tf.variable_scope('score'):\n",
    "\n",
    "            softmax_weights = tf.get_variable(name='softmax_weights', shape=[self.num_units, self.num_classes])\n",
    "            softmax_bias = tf.get_variable(name='softmax_bias', shape=[self.num_classes])\n",
    "            logits = tf.matmul(self.model[0][-1], softmax_weights) + softmax_bias\n",
    "            probs = tf.nn.softmax(logits)\n",
    "            prediction = tf.argmax(probs, 1)\n",
    "            accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.cast(prediction, tf.int32), self.input_output[1]), tf.float32))\n",
    "            tf.summary.scalar(name='accuracy', tensor=accuracy)\n",
    "\n",
    "            \n",
    "        return (logits, accuracy, prediction)\n",
    "    \n",
    "    @lazy_property\n",
    "    def cost(self):        \n",
    "            \n",
    "        with tf.name_scope('cost'):\n",
    "            cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.score[0], labels=self.input_output[1]))\n",
    "            tf.summary.scalar(name='loss', tensor=cost)\n",
    "            tf.summary.histogram(name='histogram_loss', values=cost)\n",
    "            self.summary_op = tf.summary.merge_all()\n",
    "        return cost\n",
    "    \n",
    "    \n",
    "    @lazy_property\n",
    "    def optimizer(self):\n",
    "        with tf.name_scope('optimizer'):\n",
    "            return tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss=self.cost, global_step=self.global_step)\n",
    "                           \n",
    "                \n",
    "    def predict(self, sess, data):\n",
    "        testing_X = np.array([tmp_pair[0] for tmp_pair in data.testing], dtype=np.int32)\n",
    "        testing_y = np.array([tmp_pair[1] for tmp_pair in data.testing], dtype=np.int32)\n",
    "        feed_dict = {model.input_output:(testing_X, testing_y)}\n",
    "        predict_labels, predict_accuracy = sess.run([model.score[2], model.score[1]], feed_dict=feed_dict)\n",
    "        print('============================Example of predictions============================')\n",
    "        for i in range(10):\n",
    "            print('-'*100)\n",
    "            print('Article: ', ''.join([data.idx2word[idx] for idx in testing_X[i]]))\n",
    "            print('Real category: ', data.label_dict[testing_y[i]])\n",
    "            print('Predicted category: ', data.label_dict[predict_labels[i]])\n",
    "            print('-'*100 + '\\n')\n",
    "        return predict_labels, predict_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train` method to train model.\n",
    "\n",
    "`train_writer` and `test_writer` used as indicator of `accuracy` and `loss` for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(data, model, args):\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        train_writer = tf.summary.FileWriter(logdir=args.LOGDIR + '/train', graph=sess.graph)\n",
    "        test_writer = tf.summary.FileWriter(logdir=args.LOGDIR + '/test')\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir=args.CHECKPOINTS_DIR)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            saver.restore(sess=sess, save_path=ckpt.model_checkpoint_path)\n",
    "            print(ckpt)\n",
    "        \n",
    "        max_iteration_num = args.NUM_EPOCH * data.TRAINING_SIZE // args.BATCH_SIZE\n",
    "        initial_step = model.global_step.eval()\n",
    "        for idx in range(initial_step, max_iteration_num):\n",
    "            batch_X, batch_y = data.next_batch_training()\n",
    "            \n",
    "            feed_dict = {model.input_output: (batch_X, batch_y)}\n",
    "            tmp_accuracy, tmp_cost, _, tmp_summary = sess.run([model.score[1], model.cost, model.optimizer, model.summary_op], feed_dict=feed_dict)\n",
    "            train_writer.add_summary(summary=tmp_summary, global_step=model.global_step.eval())\n",
    "            \n",
    "            if idx % 50 == 0:\n",
    "                print('='*100)\n",
    "                print('Step:{}, training accuracy:{:4f}'.format(model.global_step.eval(), tmp_accuracy))\n",
    "                print('Step: {} / {}, loss:{:4f}, accuracy:{:4f}'.format(idx, max_iteration_num, tmp_cost, tmp_accuracy))\n",
    "                print('='*100)\n",
    "                \n",
    "            if idx % 200 == 0:\n",
    "                test_batch_X, test_batch_y = data.next_batch_testing()\n",
    "                test_feed_dict = {model.input_output:(test_batch_X, test_batch_y)}\n",
    "                test_tmp_cost, test_tmp_accuracy, test_tmp_summary = sess.run([model.cost, model.score[1], model.summary_op], feed_dict=test_feed_dict)\n",
    "                test_writer.add_summary(summary=test_tmp_summary, global_step=model.global_step.eval())\n",
    "                print('-'*100)\n",
    "                print('Step:{}, testing accuracy:{:4f}'.format(model.global_step.eval(), test_tmp_accuracy))\n",
    "                print('Step: {} / {}, loss:{:4f}, accuracy:{:4f}'.format(idx, max_iteration_num, test_tmp_cost, test_tmp_accuracy))\n",
    "                print('-'*100)\n",
    "            \n",
    "            if idx % 500 == 0 or (idx+1) == max_iteration_num:\n",
    "                saver.save(sess=sess, save_path=os.path.join(args.CHECKPOINTS_DIR, 'text_classification_lstm.ckpt'), global_step=model.global_step.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`test` method to load the trained model and test model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(data, model, args):\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        ckpt = tf.train.latest_checkpoint(args.CHECKPOINTS_DIR)\n",
    "        print(ckpt)\n",
    "        saver.restore(sess=sess, save_path=ckpt)\n",
    "        predict_labels, predict_accuracy = model.predict(sess, data)\n",
    "        print('predict_accuracy:{:5f}'.format(predict_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing file >>>>>>>>>>>>>>>  1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "parsing file >>>>>>>>>>>>>>>  2\n",
      "----------------------------------------------------------------------------------------------------\n",
      "parsing file >>>>>>>>>>>>>>>  3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "parsing file >>>>>>>>>>>>>>>  4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "parsing file >>>>>>>>>>>>>>>  5\n",
      "----------------------------------------------------------------------------------------------------\n",
      "parsing file >>>>>>>>>>>>>>>  6\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Size of training data: 90000\n",
      "Size of testing data: 18000\n",
      "Average length of all articles 143.20944444444444\n",
      "====================================================================================================\n",
      "top 10 frequent words:\n",
      "[('系列', 106280), ('月', 93600), ('中', 84580), ('年', 77816), ('产品', 74051), ('日', 69792), ('英寸', 69460), ('华硕', 67137), ('屏幕尺寸', 63511), ('主频', 63027)]\n",
      "Total vocabulary size:300002\n",
      "====================================================================================================\n",
      "static_rnn inputs type: <class 'list'>\n",
      "static_rnn inputs len: 150\n",
      "static_rnn inputs element type: <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "static_rnn inputs element shape: <bound method Tensor.get_shape of <tf.Tensor 'RNNs_model/unstack:0' shape=(64, 128) dtype=float32>>\n",
      "====================================================================================================\n",
      "static_rnn output type: <class 'list'>\n",
      "static_rnn output length: 150\n",
      "static_rnn output element type: <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "static_rnn output element shape: (64, 128)\n",
      "static_rnn last_state type: <class 'tensorflow.python.ops.rnn_cell_impl.LSTMStateTuple'>\n",
      "last_state: LSTMStateTuple(c=<tf.Tensor 'RNNs_model/rnn/rnn/basic_lstm_cell/add_299:0' shape=(64, 128) dtype=float32>, h=<tf.Tensor 'RNNs_model/rnn/rnn/basic_lstm_cell/mul_449:0' shape=(64, 128) dtype=float32>)\n",
      "====================================================================================================\n",
      "outputs[-1] == last_state.h True\n",
      "====================================================================================================\n",
      "Training text: 医生 姓名 详细 介绍 门诊 停诊 公告 患者 就医 经验 医生 姓名 擅长 一二三四五 六日 得票 副主任医师 针灸 治疗 失眠 焦虑 抑郁 中风 偏瘫 失语 假性球麻痹 票下夜 主任医师 头皮针 治疗 神经系统疾病 多发性 抽动症 中风病 帕 票下夜 副主任医师 讲师 失眠 颈肩腰腿痛 颈椎 腰椎病 面瘫 针灸 埋线 治疗 便秘 票下夜 副主任医师 针灸 镇痛 头痛 骨折 肢体 康复 各类 疼痛 脊柱 整骨 手法 票下夜 主治医师 针刺 头皮针 艾灸 刺络 拔罐 票下夜 主治医师 芒针 巨针 腕踝针 头皮针 治疗 中 风后遗症 面瘫 腰腿痛 票下夜 主治医师 治疗 痛经 月经不调 针灸减肥 消化系统 疾病 中风 面瘫 骨关 票下夜 住院医师 治疗 排尿 障碍性 疾病 尿道综合征 尿失禁 针灸 埋线 减肥 月 票下夜 副主任医师 面瘫 颈椎病 腰椎病 肥胖症 遗尿 痛经 中 风后遗症 风湿痛 票下夜 副主任医师 三叉神经痛 面瘫 中风 强直性 脊柱炎 疾病 票下夜 副主任医师 石氏 醒脑 开窍 针刺法 治疗 脑血管意外 颈椎病 手指 麻木 夜 主治医师 胆结石 色斑 耳穴 疾病 夜 主任医师 教授 针灸 治疗 眼底 疾病 颈椎病 中风 偏瘫 胆石病 面肌 瘫痪\n",
      "Training text length: 150\n",
      "Training label: health\n",
      "====================================================================================================\n",
      "Training text: 搜狐 消息 月 日 消息 近日 多个 消息源 称 富士康 印度尼西亚 投资 亿美元 建厂 昨天 印尼 高 露面 谈论 富士康 投资 话题 富士康 发言人 称 尚未 董事会 提交 企划案 鸿海 近期 海外投资 汇总 昨天 印度尼西亚 工业部长 希 达亚特 富士康科技集团 表达 投资 印度尼西亚 兴趣 希 达亚特 记者 派遣 小组 富士康 会谈 小组 说 富士康 投资 印度尼西亚 兴趣 希 达亚特 并未 富士康 作出 投资 承诺 对此 富士康 发言人 富士康 印度尼西亚 整体 投资 环境 市场潜力 印象 深刻 探索 机会 发言人 称 富士康 公司 董事会 相关 当局 批准 发布公告 目前为止 尚未 机关 董事会 提交 企划案 投资 OOV 起于 本月 初一 外媒 报道 印度尼西亚 工业部长 透露 富士康 印度尼西亚 设厂 投资额 高 达 亿美元 投资 金额 庞大 印度尼西亚 提供 奖励 措施 包括 税务 减免 原料 进口 免税 分析 人士 称 欧美 经济 增长 缓慢 大陆 员工工资 上调 促使 鸿海 寻找 投资 机会 印度尼西亚 具备 富士康 两个 因素 拥有 充足 劳动力 地区 未来 内需 市场潜力 令狐 安\n",
      "Training text length: 150\n",
      "Training label: IT\n",
      "====================================================================================================\n",
      "Step:1, training accuracy:0.156250\n",
      "Step: 0 / 9843, loss:1.872140, accuracy:0.156250\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Testing text: 搜狐 汽车 天津港 报道 天津 路杰 国际 贸易有限公司 近日 搜狐 汽车 编辑 天津 港 路杰 国贸 处 受 双反 政策 影响 天津 港凡 涉及 原产 美国 轿车 越野车 初现 涨价 端倪 搜集 福特 猛禽 价格 万 属 皮卡车 型 猛禽 影响 价格 平稳 现店 现车 充足 美规 四门 版 猛禽 报价 万 外观 黑色 居多 详细 优惠 致电 咨询 PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "Testing text length: 150\n",
      "Testing label: auto\n",
      "====================================================================================================\n",
      "Testing text: 信息 成分 本品 成份 头孢拉定 化学 名称 氨基 环己烯 基 乙酰 氨基 甲基 氧代 硫杂 氮杂 双环 辛 烯 羧酸 结构式 参见 头孢拉定干混悬剂 医保 规格 剂型 颗粒剂 处方 处方 PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD\n",
      "Testing text length: 150\n",
      "Testing label: health\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:1, testing accuracy:0.125000\n",
      "Step: 0 / 9843, loss:1.797524, accuracy:0.125000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:51, training accuracy:0.406250\n",
      "Step: 50 / 9843, loss:1.459591, accuracy:0.406250\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:101, training accuracy:0.578125\n",
      "Step: 100 / 9843, loss:1.107363, accuracy:0.578125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:151, training accuracy:0.718750\n",
      "Step: 150 / 9843, loss:0.733177, accuracy:0.718750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:201, training accuracy:0.859375\n",
      "Step: 200 / 9843, loss:0.367010, accuracy:0.859375\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:201, testing accuracy:0.890625\n",
      "Step: 200 / 9843, loss:0.453715, accuracy:0.890625\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:251, training accuracy:0.875000\n",
      "Step: 250 / 9843, loss:0.383840, accuracy:0.875000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:301, training accuracy:0.921875\n",
      "Step: 300 / 9843, loss:0.282203, accuracy:0.921875\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:351, training accuracy:0.937500\n",
      "Step: 350 / 9843, loss:0.166749, accuracy:0.937500\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:401, training accuracy:0.968750\n",
      "Step: 400 / 9843, loss:0.142478, accuracy:0.968750\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:401, testing accuracy:0.921875\n",
      "Step: 400 / 9843, loss:0.316887, accuracy:0.921875\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Step:451, training accuracy:0.968750\n",
      "Step: 450 / 9843, loss:0.123632, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:501, training accuracy:0.875000\n",
      "Step: 500 / 9843, loss:0.277967, accuracy:0.875000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:551, training accuracy:0.921875\n",
      "Step: 550 / 9843, loss:0.241505, accuracy:0.921875\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:601, training accuracy:0.921875\n",
      "Step: 600 / 9843, loss:0.216890, accuracy:0.921875\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:601, testing accuracy:0.937500\n",
      "Step: 600 / 9843, loss:0.194237, accuracy:0.937500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:651, training accuracy:0.890625\n",
      "Step: 650 / 9843, loss:0.343670, accuracy:0.890625\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:701, training accuracy:0.906250\n",
      "Step: 700 / 9843, loss:0.293685, accuracy:0.906250\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:751, training accuracy:0.953125\n",
      "Step: 750 / 9843, loss:0.151906, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:801, training accuracy:0.968750\n",
      "Step: 800 / 9843, loss:0.088980, accuracy:0.968750\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:801, testing accuracy:0.968750\n",
      "Step: 800 / 9843, loss:0.122503, accuracy:0.968750\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:851, training accuracy:0.968750\n",
      "Step: 850 / 9843, loss:0.106993, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:901, training accuracy:0.953125\n",
      "Step: 900 / 9843, loss:0.117022, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:951, training accuracy:0.921875\n",
      "Step: 950 / 9843, loss:0.230202, accuracy:0.921875\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:1001, training accuracy:0.953125\n",
      "Step: 1000 / 9843, loss:0.174226, accuracy:0.953125\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:1001, testing accuracy:0.984375\n",
      "Step: 1000 / 9843, loss:0.083716, accuracy:0.984375\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:1051, training accuracy:0.937500\n",
      "Step: 1050 / 9843, loss:0.167096, accuracy:0.937500\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:1101, training accuracy:0.984375\n",
      "Step: 1100 / 9843, loss:0.056187, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:1151, training accuracy:0.890625\n",
      "Step: 1150 / 9843, loss:0.264124, accuracy:0.890625\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:1201, training accuracy:0.906250\n",
      "Step: 1200 / 9843, loss:0.283016, accuracy:0.906250\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:1201, testing accuracy:0.953125\n",
      "Step: 1200 / 9843, loss:0.177423, accuracy:0.953125\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:1251, training accuracy:0.953125\n",
      "Step: 1250 / 9843, loss:0.127550, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:1301, training accuracy:0.984375\n",
      "Step: 1300 / 9843, loss:0.126222, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:1351, training accuracy:0.953125\n",
      "Step: 1350 / 9843, loss:0.107569, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:1401, training accuracy:0.953125\n",
      "Step: 1400 / 9843, loss:0.152550, accuracy:0.953125\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:1401, testing accuracy:0.953125\n",
      "Step: 1400 / 9843, loss:0.090781, accuracy:0.953125\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:1451, training accuracy:0.953125\n",
      "Step: 1450 / 9843, loss:0.143218, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:1501, training accuracy:0.937500\n",
      "Step: 1500 / 9843, loss:0.231999, accuracy:0.937500\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:1551, training accuracy:0.968750\n",
      "Step: 1550 / 9843, loss:0.143119, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:1601, training accuracy:0.921875\n",
      "Step: 1600 / 9843, loss:0.234722, accuracy:0.921875\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:1601, testing accuracy:0.968750\n",
      "Step: 1600 / 9843, loss:0.130566, accuracy:0.968750\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Step:1651, training accuracy:0.937500\n",
      "Step: 1650 / 9843, loss:0.301406, accuracy:0.937500\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:1701, training accuracy:0.906250\n",
      "Step: 1700 / 9843, loss:0.202844, accuracy:0.906250\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:1751, training accuracy:0.953125\n",
      "Step: 1750 / 9843, loss:0.092781, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:1801, training accuracy:0.953125\n",
      "Step: 1800 / 9843, loss:0.259867, accuracy:0.953125\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:1801, testing accuracy:0.953125\n",
      "Step: 1800 / 9843, loss:0.151711, accuracy:0.953125\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:1851, training accuracy:0.968750\n",
      "Step: 1850 / 9843, loss:0.078406, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:1901, training accuracy:0.953125\n",
      "Step: 1900 / 9843, loss:0.257967, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:1951, training accuracy:0.937500\n",
      "Step: 1950 / 9843, loss:0.221295, accuracy:0.937500\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:2001, training accuracy:0.984375\n",
      "Step: 2000 / 9843, loss:0.065528, accuracy:0.984375\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:2001, testing accuracy:0.953125\n",
      "Step: 2000 / 9843, loss:0.310428, accuracy:0.953125\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:2051, training accuracy:0.953125\n",
      "Step: 2050 / 9843, loss:0.085026, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:2101, training accuracy:0.953125\n",
      "Step: 2100 / 9843, loss:0.160406, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:2151, training accuracy:0.984375\n",
      "Step: 2150 / 9843, loss:0.066159, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:2201, training accuracy:0.921875\n",
      "Step: 2200 / 9843, loss:0.174978, accuracy:0.921875\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:2201, testing accuracy:0.968750\n",
      "Step: 2200 / 9843, loss:0.101158, accuracy:0.968750\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:2251, training accuracy:1.000000\n",
      "Step: 2250 / 9843, loss:0.035032, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:2301, training accuracy:0.937500\n",
      "Step: 2300 / 9843, loss:0.152208, accuracy:0.937500\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:2351, training accuracy:0.984375\n",
      "Step: 2350 / 9843, loss:0.042589, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:2401, training accuracy:0.906250\n",
      "Step: 2400 / 9843, loss:0.285011, accuracy:0.906250\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:2401, testing accuracy:0.937500\n",
      "Step: 2400 / 9843, loss:0.380122, accuracy:0.937500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:2451, training accuracy:0.968750\n",
      "Step: 2450 / 9843, loss:0.114450, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:2501, training accuracy:0.953125\n",
      "Step: 2500 / 9843, loss:0.088054, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:2551, training accuracy:0.968750\n",
      "Step: 2550 / 9843, loss:0.174674, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:2601, training accuracy:0.968750\n",
      "Step: 2600 / 9843, loss:0.090836, accuracy:0.968750\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:2601, testing accuracy:0.921875\n",
      "Step: 2600 / 9843, loss:0.209059, accuracy:0.921875\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:2651, training accuracy:0.953125\n",
      "Step: 2650 / 9843, loss:0.094869, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:2701, training accuracy:0.953125\n",
      "Step: 2700 / 9843, loss:0.118900, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:2751, training accuracy:0.953125\n",
      "Step: 2750 / 9843, loss:0.129574, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:2801, training accuracy:0.953125\n",
      "Step: 2800 / 9843, loss:0.109773, accuracy:0.953125\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:2801, testing accuracy:0.906250\n",
      "Step: 2800 / 9843, loss:0.381461, accuracy:0.906250\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Step:2851, training accuracy:0.984375\n",
      "Step: 2850 / 9843, loss:0.098422, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:2901, training accuracy:1.000000\n",
      "Step: 2900 / 9843, loss:0.018299, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:2951, training accuracy:0.984375\n",
      "Step: 2950 / 9843, loss:0.058715, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:3001, training accuracy:0.953125\n",
      "Step: 3000 / 9843, loss:0.181187, accuracy:0.953125\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:3001, testing accuracy:0.937500\n",
      "Step: 3000 / 9843, loss:0.295722, accuracy:0.937500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:3051, training accuracy:0.953125\n",
      "Step: 3050 / 9843, loss:0.111026, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:3101, training accuracy:0.968750\n",
      "Step: 3100 / 9843, loss:0.131979, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:3151, training accuracy:0.968750\n",
      "Step: 3150 / 9843, loss:0.152612, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:3201, training accuracy:1.000000\n",
      "Step: 3200 / 9843, loss:0.016680, accuracy:1.000000\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:3201, testing accuracy:0.968750\n",
      "Step: 3200 / 9843, loss:0.215045, accuracy:0.968750\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:3251, training accuracy:0.984375\n",
      "Step: 3250 / 9843, loss:0.039077, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:3301, training accuracy:0.953125\n",
      "Step: 3300 / 9843, loss:0.143744, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:3351, training accuracy:0.953125\n",
      "Step: 3350 / 9843, loss:0.159557, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:3401, training accuracy:0.984375\n",
      "Step: 3400 / 9843, loss:0.026979, accuracy:0.984375\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:3401, testing accuracy:0.984375\n",
      "Step: 3400 / 9843, loss:0.066916, accuracy:0.984375\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:3451, training accuracy:0.953125\n",
      "Step: 3450 / 9843, loss:0.139190, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:3501, training accuracy:0.984375\n",
      "Step: 3500 / 9843, loss:0.048966, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:3551, training accuracy:1.000000\n",
      "Step: 3550 / 9843, loss:0.031676, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:3601, training accuracy:0.984375\n",
      "Step: 3600 / 9843, loss:0.029983, accuracy:0.984375\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:3601, testing accuracy:0.953125\n",
      "Step: 3600 / 9843, loss:0.113239, accuracy:0.953125\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:3651, training accuracy:0.984375\n",
      "Step: 3650 / 9843, loss:0.062875, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:3701, training accuracy:1.000000\n",
      "Step: 3700 / 9843, loss:0.017816, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:3751, training accuracy:0.984375\n",
      "Step: 3750 / 9843, loss:0.034854, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:3801, training accuracy:0.953125\n",
      "Step: 3800 / 9843, loss:0.099274, accuracy:0.953125\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:3801, testing accuracy:0.890625\n",
      "Step: 3800 / 9843, loss:0.312610, accuracy:0.890625\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:3851, training accuracy:1.000000\n",
      "Step: 3850 / 9843, loss:0.034665, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:3901, training accuracy:0.984375\n",
      "Step: 3900 / 9843, loss:0.057612, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:3951, training accuracy:0.968750\n",
      "Step: 3950 / 9843, loss:0.126904, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:4001, training accuracy:0.937500\n",
      "Step: 4000 / 9843, loss:0.130761, accuracy:0.937500\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:4001, testing accuracy:0.937500\n",
      "Step: 4000 / 9843, loss:0.213211, accuracy:0.937500\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Step:4051, training accuracy:1.000000\n",
      "Step: 4050 / 9843, loss:0.005292, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:4101, training accuracy:0.921875\n",
      "Step: 4100 / 9843, loss:0.199571, accuracy:0.921875\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:4151, training accuracy:0.968750\n",
      "Step: 4150 / 9843, loss:0.152275, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:4201, training accuracy:0.953125\n",
      "Step: 4200 / 9843, loss:0.124623, accuracy:0.953125\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:4201, testing accuracy:0.890625\n",
      "Step: 4200 / 9843, loss:0.429397, accuracy:0.890625\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:4251, training accuracy:0.953125\n",
      "Step: 4250 / 9843, loss:0.077435, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:4301, training accuracy:0.984375\n",
      "Step: 4300 / 9843, loss:0.028849, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:4351, training accuracy:1.000000\n",
      "Step: 4350 / 9843, loss:0.024528, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:4401, training accuracy:0.906250\n",
      "Step: 4400 / 9843, loss:0.213714, accuracy:0.906250\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:4401, testing accuracy:0.921875\n",
      "Step: 4400 / 9843, loss:0.218897, accuracy:0.921875\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:4451, training accuracy:1.000000\n",
      "Step: 4450 / 9843, loss:0.019688, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:4501, training accuracy:0.984375\n",
      "Step: 4500 / 9843, loss:0.098628, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:4551, training accuracy:0.984375\n",
      "Step: 4550 / 9843, loss:0.048965, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:4601, training accuracy:0.984375\n",
      "Step: 4600 / 9843, loss:0.038402, accuracy:0.984375\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:4601, testing accuracy:0.968750\n",
      "Step: 4600 / 9843, loss:0.168652, accuracy:0.968750\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:4651, training accuracy:0.984375\n",
      "Step: 4650 / 9843, loss:0.017533, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:4701, training accuracy:0.984375\n",
      "Step: 4700 / 9843, loss:0.043837, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:4751, training accuracy:1.000000\n",
      "Step: 4750 / 9843, loss:0.004042, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:4801, training accuracy:1.000000\n",
      "Step: 4800 / 9843, loss:0.009040, accuracy:1.000000\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:4801, testing accuracy:0.921875\n",
      "Step: 4800 / 9843, loss:0.423273, accuracy:0.921875\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:4851, training accuracy:0.984375\n",
      "Step: 4850 / 9843, loss:0.039527, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:4901, training accuracy:1.000000\n",
      "Step: 4900 / 9843, loss:0.006910, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:4951, training accuracy:0.984375\n",
      "Step: 4950 / 9843, loss:0.057771, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:5001, training accuracy:0.968750\n",
      "Step: 5000 / 9843, loss:0.075127, accuracy:0.968750\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:5001, testing accuracy:0.906250\n",
      "Step: 5000 / 9843, loss:0.314153, accuracy:0.906250\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:5051, training accuracy:0.968750\n",
      "Step: 5050 / 9843, loss:0.140832, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:5101, training accuracy:0.984375\n",
      "Step: 5100 / 9843, loss:0.035661, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:5151, training accuracy:0.921875\n",
      "Step: 5150 / 9843, loss:0.226516, accuracy:0.921875\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:5201, training accuracy:1.000000\n",
      "Step: 5200 / 9843, loss:0.027065, accuracy:1.000000\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:5201, testing accuracy:0.921875\n",
      "Step: 5200 / 9843, loss:0.242037, accuracy:0.921875\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Step:5251, training accuracy:0.984375\n",
      "Step: 5250 / 9843, loss:0.048962, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:5301, training accuracy:0.984375\n",
      "Step: 5300 / 9843, loss:0.045653, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:5351, training accuracy:0.984375\n",
      "Step: 5350 / 9843, loss:0.037936, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:5401, training accuracy:0.984375\n",
      "Step: 5400 / 9843, loss:0.032331, accuracy:0.984375\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:5401, testing accuracy:0.906250\n",
      "Step: 5400 / 9843, loss:0.599007, accuracy:0.906250\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:5451, training accuracy:0.984375\n",
      "Step: 5450 / 9843, loss:0.083189, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:5501, training accuracy:0.968750\n",
      "Step: 5500 / 9843, loss:0.136645, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:5551, training accuracy:0.968750\n",
      "Step: 5550 / 9843, loss:0.077566, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:5601, training accuracy:0.968750\n",
      "Step: 5600 / 9843, loss:0.053965, accuracy:0.968750\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:5601, testing accuracy:0.890625\n",
      "Step: 5600 / 9843, loss:0.416424, accuracy:0.890625\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:5651, training accuracy:1.000000\n",
      "Step: 5650 / 9843, loss:0.023171, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:5701, training accuracy:0.984375\n",
      "Step: 5700 / 9843, loss:0.025807, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:5751, training accuracy:0.984375\n",
      "Step: 5750 / 9843, loss:0.033034, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:5801, training accuracy:0.953125\n",
      "Step: 5800 / 9843, loss:0.105285, accuracy:0.953125\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:5801, testing accuracy:0.984375\n",
      "Step: 5800 / 9843, loss:0.042105, accuracy:0.984375\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:5851, training accuracy:1.000000\n",
      "Step: 5850 / 9843, loss:0.026237, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:5901, training accuracy:0.968750\n",
      "Step: 5900 / 9843, loss:0.087230, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:5951, training accuracy:0.937500\n",
      "Step: 5950 / 9843, loss:0.276877, accuracy:0.937500\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:6001, training accuracy:0.968750\n",
      "Step: 6000 / 9843, loss:0.070668, accuracy:0.968750\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:6001, testing accuracy:0.906250\n",
      "Step: 6000 / 9843, loss:0.533544, accuracy:0.906250\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:6051, training accuracy:1.000000\n",
      "Step: 6050 / 9843, loss:0.015281, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:6101, training accuracy:0.984375\n",
      "Step: 6100 / 9843, loss:0.053662, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:6151, training accuracy:0.968750\n",
      "Step: 6150 / 9843, loss:0.123248, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:6201, training accuracy:1.000000\n",
      "Step: 6200 / 9843, loss:0.007541, accuracy:1.000000\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:6201, testing accuracy:0.953125\n",
      "Step: 6200 / 9843, loss:0.278728, accuracy:0.953125\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:6251, training accuracy:0.984375\n",
      "Step: 6250 / 9843, loss:0.039372, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:6301, training accuracy:1.000000\n",
      "Step: 6300 / 9843, loss:0.017564, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:6351, training accuracy:0.968750\n",
      "Step: 6350 / 9843, loss:0.079771, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:6401, training accuracy:0.984375\n",
      "Step: 6400 / 9843, loss:0.023761, accuracy:0.984375\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:6401, testing accuracy:0.953125\n",
      "Step: 6400 / 9843, loss:0.168422, accuracy:0.953125\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Step:6451, training accuracy:1.000000\n",
      "Step: 6450 / 9843, loss:0.026251, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:6501, training accuracy:0.953125\n",
      "Step: 6500 / 9843, loss:0.192127, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:6551, training accuracy:0.984375\n",
      "Step: 6550 / 9843, loss:0.044971, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:6601, training accuracy:0.968750\n",
      "Step: 6600 / 9843, loss:0.105416, accuracy:0.968750\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:6601, testing accuracy:0.937500\n",
      "Step: 6600 / 9843, loss:0.249497, accuracy:0.937500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:6651, training accuracy:1.000000\n",
      "Step: 6650 / 9843, loss:0.005533, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:6701, training accuracy:0.906250\n",
      "Step: 6700 / 9843, loss:0.408256, accuracy:0.906250\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:6751, training accuracy:0.906250\n",
      "Step: 6750 / 9843, loss:0.156186, accuracy:0.906250\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:6801, training accuracy:0.953125\n",
      "Step: 6800 / 9843, loss:0.137640, accuracy:0.953125\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:6801, testing accuracy:0.921875\n",
      "Step: 6800 / 9843, loss:0.298172, accuracy:0.921875\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:6851, training accuracy:0.984375\n",
      "Step: 6850 / 9843, loss:0.031291, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:6901, training accuracy:0.968750\n",
      "Step: 6900 / 9843, loss:0.056225, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:6951, training accuracy:0.968750\n",
      "Step: 6950 / 9843, loss:0.150354, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:7001, training accuracy:1.000000\n",
      "Step: 7000 / 9843, loss:0.020267, accuracy:1.000000\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:7001, testing accuracy:0.984375\n",
      "Step: 7000 / 9843, loss:0.053975, accuracy:0.984375\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:7051, training accuracy:0.984375\n",
      "Step: 7050 / 9843, loss:0.041724, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:7101, training accuracy:0.984375\n",
      "Step: 7100 / 9843, loss:0.037131, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:7151, training accuracy:0.984375\n",
      "Step: 7150 / 9843, loss:0.034025, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:7201, training accuracy:0.984375\n",
      "Step: 7200 / 9843, loss:0.070007, accuracy:0.984375\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:7201, testing accuracy:0.921875\n",
      "Step: 7200 / 9843, loss:0.355269, accuracy:0.921875\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:7251, training accuracy:1.000000\n",
      "Step: 7250 / 9843, loss:0.020517, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:7301, training accuracy:1.000000\n",
      "Step: 7300 / 9843, loss:0.031752, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:7351, training accuracy:0.968750\n",
      "Step: 7350 / 9843, loss:0.234327, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:7401, training accuracy:0.984375\n",
      "Step: 7400 / 9843, loss:0.024408, accuracy:0.984375\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:7401, testing accuracy:0.906250\n",
      "Step: 7400 / 9843, loss:0.323224, accuracy:0.906250\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:7451, training accuracy:0.984375\n",
      "Step: 7450 / 9843, loss:0.111500, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:7501, training accuracy:1.000000\n",
      "Step: 7500 / 9843, loss:0.017224, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:7551, training accuracy:1.000000\n",
      "Step: 7550 / 9843, loss:0.017594, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:7601, training accuracy:1.000000\n",
      "Step: 7600 / 9843, loss:0.026212, accuracy:1.000000\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:7601, testing accuracy:0.953125\n",
      "Step: 7600 / 9843, loss:0.141883, accuracy:0.953125\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Step:7651, training accuracy:0.984375\n",
      "Step: 7650 / 9843, loss:0.085423, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:7701, training accuracy:0.968750\n",
      "Step: 7700 / 9843, loss:0.182175, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:7751, training accuracy:0.953125\n",
      "Step: 7750 / 9843, loss:0.157031, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:7801, training accuracy:0.984375\n",
      "Step: 7800 / 9843, loss:0.040249, accuracy:0.984375\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:7801, testing accuracy:0.953125\n",
      "Step: 7800 / 9843, loss:0.123090, accuracy:0.953125\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:7851, training accuracy:1.000000\n",
      "Step: 7850 / 9843, loss:0.004800, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:7901, training accuracy:0.968750\n",
      "Step: 7900 / 9843, loss:0.083941, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:7951, training accuracy:0.968750\n",
      "Step: 7950 / 9843, loss:0.081409, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:8001, training accuracy:0.984375\n",
      "Step: 8000 / 9843, loss:0.048061, accuracy:0.984375\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:8001, testing accuracy:0.921875\n",
      "Step: 8000 / 9843, loss:0.341440, accuracy:0.921875\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:8051, training accuracy:1.000000\n",
      "Step: 8050 / 9843, loss:0.004728, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:8101, training accuracy:1.000000\n",
      "Step: 8100 / 9843, loss:0.011825, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:8151, training accuracy:0.984375\n",
      "Step: 8150 / 9843, loss:0.045033, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:8201, training accuracy:1.000000\n",
      "Step: 8200 / 9843, loss:0.008671, accuracy:1.000000\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:8201, testing accuracy:0.953125\n",
      "Step: 8200 / 9843, loss:0.110518, accuracy:0.953125\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:8251, training accuracy:1.000000\n",
      "Step: 8250 / 9843, loss:0.012129, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:8301, training accuracy:1.000000\n",
      "Step: 8300 / 9843, loss:0.014804, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:8351, training accuracy:0.984375\n",
      "Step: 8350 / 9843, loss:0.090427, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:8401, training accuracy:0.984375\n",
      "Step: 8400 / 9843, loss:0.036064, accuracy:0.984375\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:8401, testing accuracy:0.968750\n",
      "Step: 8400 / 9843, loss:0.157791, accuracy:0.968750\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:8451, training accuracy:0.953125\n",
      "Step: 8450 / 9843, loss:0.202475, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:8501, training accuracy:1.000000\n",
      "Step: 8500 / 9843, loss:0.015208, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:8551, training accuracy:0.968750\n",
      "Step: 8550 / 9843, loss:0.130300, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:8601, training accuracy:0.984375\n",
      "Step: 8600 / 9843, loss:0.029622, accuracy:0.984375\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:8601, testing accuracy:0.968750\n",
      "Step: 8600 / 9843, loss:0.124821, accuracy:0.968750\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:8651, training accuracy:0.968750\n",
      "Step: 8650 / 9843, loss:0.092280, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:8701, training accuracy:0.984375\n",
      "Step: 8700 / 9843, loss:0.083147, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:8751, training accuracy:1.000000\n",
      "Step: 8750 / 9843, loss:0.010593, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:8801, training accuracy:1.000000\n",
      "Step: 8800 / 9843, loss:0.009836, accuracy:1.000000\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:8801, testing accuracy:0.937500\n",
      "Step: 8800 / 9843, loss:0.399691, accuracy:0.937500\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Step:8851, training accuracy:0.953125\n",
      "Step: 8850 / 9843, loss:0.083620, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:8901, training accuracy:0.984375\n",
      "Step: 8900 / 9843, loss:0.117717, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:8951, training accuracy:0.953125\n",
      "Step: 8950 / 9843, loss:0.090976, accuracy:0.953125\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:9001, training accuracy:0.984375\n",
      "Step: 9000 / 9843, loss:0.037488, accuracy:0.984375\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:9001, testing accuracy:0.937500\n",
      "Step: 9000 / 9843, loss:0.247843, accuracy:0.937500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:9051, training accuracy:0.968750\n",
      "Step: 9050 / 9843, loss:0.097935, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:9101, training accuracy:1.000000\n",
      "Step: 9100 / 9843, loss:0.002535, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:9151, training accuracy:0.968750\n",
      "Step: 9150 / 9843, loss:0.062974, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:9201, training accuracy:0.968750\n",
      "Step: 9200 / 9843, loss:0.106489, accuracy:0.968750\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:9201, testing accuracy:0.953125\n",
      "Step: 9200 / 9843, loss:0.184761, accuracy:0.953125\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:9251, training accuracy:1.000000\n",
      "Step: 9250 / 9843, loss:0.021026, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:9301, training accuracy:0.984375\n",
      "Step: 9300 / 9843, loss:0.053036, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:9351, training accuracy:0.968750\n",
      "Step: 9350 / 9843, loss:0.236272, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:9401, training accuracy:1.000000\n",
      "Step: 9400 / 9843, loss:0.011261, accuracy:1.000000\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:9401, testing accuracy:0.953125\n",
      "Step: 9400 / 9843, loss:0.206923, accuracy:0.953125\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:9451, training accuracy:1.000000\n",
      "Step: 9450 / 9843, loss:0.022452, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:9501, training accuracy:0.968750\n",
      "Step: 9500 / 9843, loss:0.083325, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:9551, training accuracy:1.000000\n",
      "Step: 9550 / 9843, loss:0.018692, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:9601, training accuracy:0.984375\n",
      "Step: 9600 / 9843, loss:0.065136, accuracy:0.984375\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:9601, testing accuracy:0.937500\n",
      "Step: 9600 / 9843, loss:0.434192, accuracy:0.937500\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "Step:9651, training accuracy:0.968750\n",
      "Step: 9650 / 9843, loss:0.134934, accuracy:0.968750\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:9701, training accuracy:0.984375\n",
      "Step: 9700 / 9843, loss:0.031806, accuracy:0.984375\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:9751, training accuracy:1.000000\n",
      "Step: 9750 / 9843, loss:0.010805, accuracy:1.000000\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Step:9801, training accuracy:0.984375\n",
      "Step: 9800 / 9843, loss:0.060985, accuracy:0.984375\n",
      "====================================================================================================\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Step:9801, testing accuracy:0.937500\n",
      "Step: 9800 / 9843, loss:0.284007, accuracy:0.937500\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    args = Arguments()\n",
    "    data = DataGenerator(args)\n",
    "    \n",
    "    # for training\n",
    "    model = TextClassificationModel(args)\n",
    "    train(data, model, args)\n",
    "    \n",
    "    \n",
    "    # after training model, testing it using whole testing data\n",
    "    # for testing\n",
    "    # model = TextClassificationModel(args, is_training=False)\n",
    "    # test(data, model, args) # predict_accuracy:0.769333\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
